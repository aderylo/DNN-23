{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISUBZbOTVZxn"
      },
      "source": [
        "# Low-shot visual anomaly detection (v2.1)\n",
        "\n",
        "*This is the updated version of the homework with some additional clarifications and changes in the task descriptions (see slack channel for details). The code remains untouched.*\n",
        "\n",
        "In this notebook you'll investigate visual anomaly detection in a typical industrial setting - we don't have much data and we can train only only normal (non-anomalous) examples.\n",
        "Read the [PADIM paper](https://arxiv.org/pdf/2011.08785.pdf) carefully.\n",
        "The code here is based on the original implementation from its authors.\n",
        "\n",
        "If you have any questions - please write them on slack in the channel.\n",
        "\n",
        "### Bibliography\n",
        "\n",
        "1. Defard, T., Setkov, A., Loesch, A., & Audigier, R. (2021). [Padim: a patch distribution modeling framework for anomaly detection and localization](https://arxiv.org/pdf/2011.08785.pdf). In International Conference on Pattern Recognition (pp. 475-489). Cham: Springer International Publishing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gwf82SgVZxo"
      },
      "source": [
        "## Data\n",
        "\n",
        "In case of any problems - please visit [MVTec AD](https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads) to get the access to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yRQ3gPIVZxp"
      },
      "outputs": [],
      "source": [
        "# %pip install --quiet gdown  # for those who don't run it on Google Colab\n",
        "# !gdown -q '1r7WJeDb-E5zzgQSOx7F7bNWg8kYX3yKE'\n",
        "# !gdown -q '1Kb420ygkN1iBni5Iy_-psLGNoY0gQFk9'\n",
        "# !gdown -q '12wDP9I3aVIr1qLekWY3GLhQO7c6SRhGn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "liTm9VH-VZxp"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import tarfile\n",
        "\n",
        "DATA_PATH = Path('./mvtec_anomaly_detection')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "for class_name in ['bottle', 'metal_nut', 'transistor']:\n",
        "    if not (DATA_PATH / class_name).exists():\n",
        "        with tarfile.open(class_name + '.tar.xz') as tar:\n",
        "            tar.extractall(path=DATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQyQYffqVZxq"
      },
      "source": [
        "## PADIM implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uvPuyg5vVZxq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "from random import sample\n",
        "from typing import cast, Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends, torch.backends.mps\n",
        "import torch.nn.functional as F\n",
        "from numpy.typing import NDArray\n",
        "from matplotlib import colors\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage import morphology\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models import wide_resnet50_2, resnet18, Wide_ResNet50_2_Weights, ResNet18_Weights\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "FloatNDArray = NDArray[np.float32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SuSoeQJMVZxr"
      },
      "outputs": [],
      "source": [
        "# Leave it as is if you're unsure, this notebook will guess this for you below.\n",
        "DEVICE: Optional[torch.device] = None\n",
        "SEED: int = 42  # do not modify\n",
        "\n",
        "plt.style.use(\"dark_background\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6q4z2STVZxr"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed: int = 0) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def get_best_device_for_pytorch() -> torch.device:\n",
        "    if torch.cuda.is_available():\n",
        "        device_str = \"cuda\"     # GPU\n",
        "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "        device_str = \"mps\"      # Apple silicon\n",
        "    else:\n",
        "        device_str = \"cpu\"      # CPU\n",
        "    return torch.device(device_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VJUMYdKqVZxr",
        "outputId": "3c7a5fd5-4d39-4520-f9e1-85e11058e48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch with mps backend.\n",
            "Seeded everything with 42.\n"
          ]
        }
      ],
      "source": [
        "if not DEVICE:\n",
        "    DEVICE = get_best_device_for_pytorch()\n",
        "print(f\"Using PyTorch with {DEVICE} backend.\")\n",
        "\n",
        "seed_all(SEED)\n",
        "print(f\"Seeded everything with {SEED}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YAV-eWoVZxs"
      },
      "source": [
        "### MVTecDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FFDn_Y7xVZxt"
      },
      "outputs": [],
      "source": [
        "class MVTecDataset(Dataset[Tuple[torch.Tensor, int, torch.Tensor]]):\n",
        "    \"\"\"MVTec dataset of industrial objects with and without anomalies.\n",
        "\n",
        "    Yields (x, y, mask) tuples where:\n",
        "    - x is an RGB image from the class, as float tensor of shape (3, cropsize, cropsize);\n",
        "    - y is an int, 0 for good images, 1 for anomalous images;\n",
        "    - mask is 0 for normal pixels, 1 for anomalous pixels, as float tensor of shape (1, cropsize, cropsize).\n",
        "\n",
        "    Source: https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master/blob/main/datasets/mvtec.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path: Path, class_name: str = 'bottle',\n",
        "                 is_train: bool = True, resize: int = 256, cropsize: int = 224, return_only_indices=False):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.class_name = class_name\n",
        "        assert (dataset_path / class_name).is_dir(), f'Dataset class not found: {dataset_path / class_name}'\n",
        "        self.is_train = is_train\n",
        "\n",
        "        self.resize = resize\n",
        "        self.cropsize = cropsize\n",
        "\n",
        "        # load dataset\n",
        "        self.x, self.y, self.mask = self.load_dataset_folder()\n",
        "\n",
        "        # set transforms\n",
        "        self.transform_x = T.Compose([T.Resize(resize, Image.LANCZOS),\n",
        "                                      T.CenterCrop(cropsize),\n",
        "                                      T.ToTensor(),\n",
        "                                      T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                  std=[0.229, 0.224, 0.225])])\n",
        "        self.transform_mask = T.Compose([T.Resize(resize, Image.NEAREST),\n",
        "                                         T.CenterCrop(cropsize),\n",
        "                                         T.ToTensor()])\n",
        "\n",
        "        self.return_only_indices = return_only_indices\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int, torch.Tensor]:\n",
        "        if self.return_only_indices:  # Used for checking the answer of T1.1.\n",
        "            return idx\n",
        "\n",
        "        x, y, mask = self.x[idx], self.y[idx], self.mask[idx]\n",
        "\n",
        "        x = Image.open(x).convert('RGB')\n",
        "        x = cast(torch.Tensor, self.transform_x(x))\n",
        "\n",
        "        if y == 0:\n",
        "            mask = torch.zeros([1, self.cropsize, self.cropsize])\n",
        "        else:\n",
        "            assert mask is not None\n",
        "            mask = Image.open(mask)\n",
        "            mask = cast(torch.Tensor, self.transform_mask(mask))\n",
        "\n",
        "        return x, y, mask\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.x)\n",
        "\n",
        "    def load_dataset_folder(self) -> Tuple[List[Path], List[int], List[Optional[Path]]]:\n",
        "        phase = 'train' if self.is_train else 'test'\n",
        "        x: List[Path] = []\n",
        "        y: List[int] = []\n",
        "        mask: List[Optional[Path]] = []\n",
        "\n",
        "        img_dir = self.dataset_path / self.class_name / phase\n",
        "        gt_dir = self.dataset_path / self.class_name / 'ground_truth'\n",
        "\n",
        "        for img_type_dir in sorted(img_dir.iterdir()):\n",
        "            # Load images.\n",
        "            if not img_type_dir.is_dir():\n",
        "                continue\n",
        "            img_fpath_list = sorted(img_type_dir.glob('*.png'))\n",
        "            x.extend(img_fpath_list)\n",
        "\n",
        "            # Load ground-truth labels and masks.\n",
        "            if img_type_dir.name == 'good':\n",
        "                y.extend([0] * len(img_fpath_list))\n",
        "                mask.extend([None] * len(img_fpath_list))\n",
        "            else:\n",
        "                y.extend([1] * len(img_fpath_list))\n",
        "                mask.extend([gt_dir / img_type_dir.name / (f.stem + '_mask.png')\n",
        "                            for f in img_fpath_list])\n",
        "\n",
        "        assert len(x) == len(y) == len(mask), 'Number of x, y, and mask should be the same.'\n",
        "        return x, y, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jc3w7-nVVZxt"
      },
      "outputs": [],
      "source": [
        "def sample_idx(number_of_features: int, max_number_of_features: int) -> torch.Tensor:\n",
        "    assert number_of_features <= max_number_of_features\n",
        "    return torch.tensor(sample(range(0, max_number_of_features), number_of_features))\n",
        "\n",
        "\n",
        "def denormalization(x: FloatNDArray) -> NDArray[np.uint8]:\n",
        "    \"\"\"Denormalize with ImageNet values.\"\"\"\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    return (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n",
        "\n",
        "\n",
        "def embedding_concat(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Concatenate embeddings (along the channel dimension, upscaling y to match x).\n",
        "\n",
        "    Args:\n",
        "        x: Tensor of shape (B, C1, H1, W1).\n",
        "        y: Tensor of shape (B, C2, H2, W2).\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape is (B, C1 + C2, H1, W1).\n",
        "    \"\"\"\n",
        "    B, C1, H1, W1 = x.size()\n",
        "    _, C2, H2, W2 = y.size()\n",
        "    s = int(H1 / H2)\n",
        "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
        "    x = x.view(B, C1, s * s, H2, W2)\n",
        "    z = torch.zeros(B, C1 + C2, s * s, H2, W2).to(x.device)\n",
        "    for i in range(s * s):\n",
        "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), dim=1)\n",
        "    z = z.view(B, -1, H2 * W2)\n",
        "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
        "    return z\n",
        "\n",
        "def concatenate_embeddings_from_all_layers(layer_outputs: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        embedding_vectors = layer_outputs['layer1']\n",
        "        for layer_name in ['layer2', 'layer3']:\n",
        "            embedding_vectors = embedding_concat(embedding_vectors, layer_outputs[layer_name])\n",
        "        return embedding_vectors\n",
        "\n",
        "def plot_fig(test_img, scores, gts, threshold: float, save_dir: Path, class_name: str):\n",
        "    num = len(scores)\n",
        "    vmax = scores.max() * 255.\n",
        "    vmin = scores.min() * 255.\n",
        "    for i in range(num):\n",
        "        img = test_img[i]\n",
        "        img = denormalization(img)\n",
        "        gt = gts[i].transpose(1, 2, 0).squeeze()\n",
        "        heat_map = scores[i] * 255\n",
        "        mask = scores[i]\n",
        "        mask[mask > threshold] = 1\n",
        "        mask[mask <= threshold] = 0\n",
        "        kernel = morphology.disk(4)\n",
        "        mask = morphology.opening(mask, kernel)\n",
        "        mask *= 255\n",
        "        vis_img = mark_boundaries(img, mask, color=(1, 0, 0), mode='thick')\n",
        "        fig_img, ax_img = plt.subplots(1, 5, figsize=(12, 3))\n",
        "        fig_img.subplots_adjust(right=0.9)\n",
        "        norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
        "        for ax_i in ax_img:\n",
        "            ax_i.axes.xaxis.set_visible(False)\n",
        "            ax_i.axes.yaxis.set_visible(False)\n",
        "        ax_img[0].imshow(img)\n",
        "        ax_img[0].title.set_text('Image')\n",
        "        ax_img[1].imshow(gt, cmap='gray')\n",
        "        ax_img[1].title.set_text('GroundTruth')\n",
        "        ax = ax_img[2].imshow(heat_map, cmap='jet', norm=norm)\n",
        "        ax_img[2].imshow(img, cmap='gray', interpolation='none')\n",
        "        ax_img[2].imshow(heat_map, cmap='jet', alpha=0.5, interpolation='none')\n",
        "        ax_img[2].title.set_text('Predicted heat map')\n",
        "        ax_img[3].imshow(mask, cmap='gray')\n",
        "        ax_img[3].title.set_text('Predicted mask')\n",
        "        ax_img[4].imshow(vis_img)\n",
        "        ax_img[4].title.set_text('Segmentation result')\n",
        "        left = 0.92\n",
        "        bottom = 0.15\n",
        "        width = 0.015\n",
        "        height = 1 - 2 * bottom\n",
        "        rect = [left, bottom, width, height]\n",
        "        cbar_ax = fig_img.add_axes(rect)\n",
        "        cb = plt.colorbar(ax, shrink=0.6, cax=cbar_ax, fraction=0.046)\n",
        "        cb.ax.tick_params(labelsize=8)\n",
        "        font = {\n",
        "            'family': 'serif',\n",
        "            'color': 'black',\n",
        "            'weight': 'normal',\n",
        "            'size': 8,\n",
        "        }\n",
        "        cb.set_label('Anomaly Score', fontdict=font)\n",
        "\n",
        "        fig_img.savefig(save_dir / f'{class_name}_{i}', dpi=100)\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VGs7EmL9VZxt"
      },
      "outputs": [],
      "source": [
        "def get_feature_extractor(arch: str) -> nn.Module:\n",
        "    if arch == 'resnet18':\n",
        "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1, progress=True)\n",
        "        # t_d = 448\n",
        "        # d = 40\n",
        "    elif arch == 'wide_resnet50_2':\n",
        "        model = wide_resnet50_2(weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1, progress=True)\n",
        "        # t_d = 1792\n",
        "        # d = 550\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzRgYQYxVZxu"
      },
      "source": [
        "### PADIM class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "m5AzS1u1VZxu"
      },
      "outputs": [],
      "source": [
        "class PADIM():\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: str,\n",
        "            device: torch.device,\n",
        "            save_path: Path,\n",
        "            backbone_features_idx: torch.Tensor,\n",
        "            class_names: List[str] = [\"bottle\"],\n",
        "            plot_metrics: bool = False,\n",
        "    ) -> None:\n",
        "        self.arch = backbone\n",
        "        self.device = device\n",
        "        self.model = get_feature_extractor(backbone)\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.feature_subset_indices = backbone_features_idx\n",
        "        self.feature_subset_indices.to(device)\n",
        "\n",
        "        self.outputs: Dict[str, torch.Tensor] = {}\n",
        "\n",
        "        self.class_names = class_names\n",
        "        self.save_path = save_path\n",
        "        self.plot_metrics = plot_metrics\n",
        "\n",
        "        self.setup_hooks()\n",
        "        (self.save_path / f'temp_{self.arch}').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.mean: FloatNDArray  # shape (C, H * W)\n",
        "        self.cov: FloatNDArray  # shape (C, C, H * W)\n",
        "\n",
        "    def setup_hooks(self):\n",
        "        \"\"\"Setup hooks to store model's intermediate outputs.\"\"\"\n",
        "        self.model.layer1[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer1': x}))\n",
        "        self.model.layer2[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer2': x}))\n",
        "        self.model.layer3[-1].register_forward_hook(lambda _, __, x: self.outputs.update({'layer3': x}))\n",
        "\n",
        "    def train_and_test(self, train_dataloader: DataLoader, test_dataloader: DataLoader) -> float:\n",
        "        self.train(train_dataloader)\n",
        "        return self.test(test_dataloader)\n",
        "\n",
        "    def train(self, train_dataloader: DataLoader) -> None:\n",
        "        self.train_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n",
        "        for x, _, _ in tqdm(train_dataloader, desc='Feature extraction (train)'):\n",
        "            # Run model prediction.\n",
        "            with torch.no_grad():\n",
        "                _ = self.model(x.to(DEVICE))\n",
        "            # Get intermediate layer outputs.\n",
        "            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3'], list(self.outputs.keys())\n",
        "            for k, v in self.outputs.items():\n",
        "                self.train_outputs[k].append(v.cpu().detach())\n",
        "            # Reset hook outputs.\n",
        "            self.outputs = {}\n",
        "\n",
        "        embedding_vectors = concatenate_embeddings_from_all_layers(\n",
        "            {k: torch.cat(v, 0) for k, v in self.train_outputs.items()})\n",
        "        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n",
        "\n",
        "        self.mean, self.cov = self.estimate_multivariate_gaussian(embedding_vectors_subset)\n",
        "        del(self.train_outputs)\n",
        "\n",
        "    def estimate_multivariate_gaussian(self, embedding_vectors: torch.Tensor\n",
        "                                       ) -> Tuple[FloatNDArray, FloatNDArray]:\n",
        "        \"\"\"Calculates multivariate Gaussian distribution.\n",
        "\n",
        "        Takes embeddings of shape (N, C, H, W).\n",
        "        Returns (mean, covariance) of shape (C, H * W) and (C, C, H * W) respectively.\n",
        "        \"\"\"\n",
        "        B, C, H, W = embedding_vectors.size()\n",
        "        embedding_vectors = embedding_vectors.view(B, C, H * W)\n",
        "        mean = torch.mean(embedding_vectors, dim=0).numpy()\n",
        "        cov = torch.zeros(C, C, H * W).numpy()\n",
        "        I = np.identity(C)\n",
        "        for i in tqdm(range(H * W), desc=\"Covariance estimation\"):\n",
        "            cov[:, :, i] = np.cov(embedding_vectors[:, :, i].numpy(), rowvar=False) + 0.01 * I\n",
        "        return mean, cov\n",
        "\n",
        "    def test(self, test_dataloader: DataLoader) -> float:\n",
        "        self.test_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n",
        "        test_imgs: List[FloatNDArray] = []\n",
        "        gt_list: List[NDArray[Any]] = []\n",
        "        gt_mask_list: List[FloatNDArray] = []\n",
        "\n",
        "        # Extract test set features.\n",
        "        for x, y, mask in tqdm(test_dataloader, desc='Feature extraction (test)', disable=False):\n",
        "            x_shape = x.shape\n",
        "            test_imgs.extend(x.cpu().detach().numpy())\n",
        "            gt_list.extend(y.cpu().detach().numpy())\n",
        "            gt_mask_list.extend(mask.cpu().detach().numpy())\n",
        "            # Run model prediction.\n",
        "            with torch.no_grad():\n",
        "                _ = self.model(x.to(DEVICE))\n",
        "            # Get intermediate layer outputs.\n",
        "            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3']\n",
        "            for k, v in self.outputs.items():\n",
        "                self.test_outputs[k].append(v.cpu().detach())\n",
        "            # Reset hook outputs.\n",
        "            self.outputs = {}\n",
        "        gt_mask = np.asarray(gt_mask_list)  # shape (len(test_dataset), 1, H, W)\n",
        "\n",
        "        embedding_vectors = concatenate_embeddings_from_all_layers(\n",
        "            {k: torch.cat(v, 0) for k, v in self.test_outputs.items()})\n",
        "        # shape (len(test_dataset), len(feature_subset_indices), H1, W1)\n",
        "        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n",
        "\n",
        "        distances = self.calculate_distances(embedding_vectors_subset)\n",
        "        score_map = self.prepare_anomaly_map((x_shape[2], x_shape[3]), distances)\n",
        "\n",
        "        img_fpr, img_tpr, img_auroc = self.calculate_auroc_image_level(score_map, gt_list)\n",
        "        pxl_fpr, pxl_tpr, pxl_auroc = self.calculate_auroc_pixel_level(score_map, gt_mask)\n",
        "\n",
        "        if self.plot_metrics:\n",
        "            print(f'[TEST] Image AUROC: {img_auroc:.3f}')\n",
        "            print(f'[TEST] Pixel AUROC: {pxl_auroc:.3f}')\n",
        "            threshold = self.calculate_optimal_threshold(score_map, gt_mask)\n",
        "            self.plot_test_results_for_class(gt_mask_list, test_imgs, score_map, threshold, img_fpr, img_tpr, img_auroc, pxl_fpr, pxl_tpr, pxl_auroc)\n",
        "\n",
        "        return pxl_auroc\n",
        "\n",
        "    # TODO: Some of your code for Task 1 goes here. You can add more functions if needed, but use the ones below - we will use them for checking your solution.\n",
        "    def test_permutation_importance(self, val_dataloader: DataLoader, features_to_permute: List[int]) -> List[float]:\n",
        "        \"\"\"Runs a series of tests on `val_dataloader`.\n",
        "        Returns a list of pixelwise AUROCs, where the n-th element of the list is generated by testing the embeddings from `permute_feature(embeddings, features_to_permute[n]).\"\"\"\n",
        "        self.test_outputs: Dict[str, List[torch.Tensor]] = {'layer1': [], 'layer2': [], 'layer3': []}\n",
        "        test_imgs: List[FloatNDArray] = []\n",
        "        gt_list: List[NDArray[Any]] = []\n",
        "        gt_mask_list: List[FloatNDArray] = []\n",
        "\n",
        "        # Extract test set features.\n",
        "        for x, y, mask in tqdm(val_dataloader, desc='Feature extraction (test)', disable=False):\n",
        "            x_shape = x.shape\n",
        "            test_imgs.extend(x.cpu().detach().numpy())\n",
        "            gt_list.extend(y.cpu().detach().numpy())\n",
        "            gt_mask_list.extend(mask.cpu().detach().numpy())\n",
        "            # Run model prediction.\n",
        "            with torch.no_grad():\n",
        "                _ = self.model(x.to(DEVICE))\n",
        "            # Get intermediate layer outputs.\n",
        "            assert list(self.outputs.keys())  == ['layer1', 'layer2', 'layer3']\n",
        "            for k, v in self.outputs.items():\n",
        "                self.test_outputs[k].append(v.cpu().detach())\n",
        "            # Reset hook outputs.\n",
        "            self.outputs = {}\n",
        "        gt_mask = np.asarray(gt_mask_list)  # shape (len(test_dataset), 1, H, W)\n",
        "\n",
        "        embedding_vectors = concatenate_embeddings_from_all_layers(\n",
        "            {k: torch.cat(v, 0) for k, v in self.test_outputs.items()})\n",
        "        # shape (len(test_dataset), len(feature_subset_indices), H1, W1)\n",
        "        embedding_vectors_subset = torch.index_select(embedding_vectors, 1, self.feature_subset_indices.cpu())\n",
        "\n",
        "        pxl_auroc_list = []\n",
        "        for feature in tqdm(list(features_to_permute), desc=\"Scoring feature importance\"):\n",
        "            permuted_embedding_vecs = self.permute_feature(embedding_vectors_subset, feature)\n",
        "\n",
        "            distances = self.calculate_distances(permuted_embedding_vecs)\n",
        "            score_map = self.prepare_anomaly_map((x_shape[2], x_shape[3]), distances)\n",
        "\n",
        "            pxl_fpr, pxl_tpr, pxl_auroc = self.calculate_auroc_pixel_level(score_map, gt_mask)\n",
        "            pxl_auroc_list.append(pxl_auroc)\n",
        "\n",
        "        return pxl_auroc_list\n",
        "\n",
        "    def permute_feature(self, embedding_vectors_subset: torch.Tensor, number_of_feature_to_permute: int) -> torch.Tensor:\n",
        "        \"\"\"Permutes the embeddings.\n",
        "\n",
        "        Takes embeddings of shape (N, C, H, W) and feature number to permute.\n",
        "        Returns embeddings with the same shape. See the description of T1 for the details.\n",
        "        \"\"\"\n",
        "        tensor = embedding_vectors_subset.clone()\n",
        "        b, c, h, w = tensor.shape\n",
        "        perm_h = torch.randperm(h).to(tensor.device)\n",
        "        perm_w = torch.randperm(w).to(tensor.device)\n",
        "\n",
        "        tensor[:, number_of_feature_to_permute, :, :] = tensor[:, number_of_feature_to_permute, perm_h, :]\n",
        "        tensor[:, number_of_feature_to_permute, :, :] = tensor[:, number_of_feature_to_permute, :, perm_w]\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    # TODO: End of your code for Task 1 (here)\n",
        "\n",
        "    def plot_test_results_for_class(self, gt_mask_list, test_imgs,\n",
        "                                    score_map, threshold: float,\n",
        "                                    img_fpr, img_tpr, img_auroc: float,\n",
        "                                    pxl_fpr, pxl_tpr, pxl_auroc: float):\n",
        "        _, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "        ax[0].plot(img_fpr, img_tpr, label=f'Image AUROC: {img_auroc:.3f}')\n",
        "        ax[1].plot(pxl_fpr, pxl_tpr, label=f'Pixel AUROC: {pxl_auroc:.3f}')\n",
        "\n",
        "        save_dir = self.save_path / f'pictures_{self.arch}'\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        plot_fig(test_imgs, score_map, gt_mask_list,\n",
        "                 threshold, save_dir, \"\")\n",
        "\n",
        "    def calculate_auroc_image_level(self, score_map: FloatNDArray, gt_list: List[NDArray[Any]]) -> Tuple[FloatNDArray, FloatNDArray, float]:\n",
        "        \"\"\"Calculate image-level AUROC score.\"\"\"\n",
        "        img_scores = score_map.reshape(score_map.shape[0], -1).max(axis=1)\n",
        "        fpr, tpr, _ = roc_curve(gt_list, img_scores)  # false-positive-rates and true-positive-rates for consecutive thresholds (for plotting).\n",
        "        img_auroc = roc_auc_score(gt_list, img_scores)\n",
        "        return fpr, tpr, float(img_auroc)\n",
        "\n",
        "    def calculate_auroc_pixel_level(self, score_map: FloatNDArray, gt_mask: FloatNDArray) -> Tuple[FloatNDArray, FloatNDArray, float]:\n",
        "        \"\"\"Calculate per-pixel level AUROC.\"\"\"\n",
        "        assert score_map.shape == gt_mask.squeeze().shape, f\"{score_map.shape=}, {gt_mask.shape=}\"\n",
        "        fpr, tpr, _ = roc_curve(gt_mask.flatten(), score_map.flatten())\n",
        "        per_pixel_auroc = roc_auc_score(gt_mask.flatten(), score_map.flatten())\n",
        "        return fpr, tpr, float(per_pixel_auroc)\n",
        "\n",
        "    def calculate_optimal_threshold(self, score_map: FloatNDArray, gt_mask: FloatNDArray) -> float:\n",
        "        \"\"\"Calculate the optimal threshold with regard to F1 score.\"\"\"\n",
        "        assert score_map.shape == gt_mask.squeeze().shape\n",
        "        precision, recall, thresholds = precision_recall_curve(\n",
        "            gt_mask.flatten(), score_map.flatten())\n",
        "        a = 2 * precision * recall\n",
        "        b = precision + recall\n",
        "        f1 = np.divide(a, b, out=np.zeros_like(a), where=(b != 0))\n",
        "        threshold = thresholds[np.argmax(f1)]\n",
        "        return threshold\n",
        "\n",
        "    def calculate_distances(self, embedding_vectors: torch.Tensor) -> FloatNDArray:\n",
        "        \"\"\"Calculate Mahalanobis distance of each embedding vector from self.mean.\n",
        "\n",
        "        For embeddings of shape (N, C, H, W), returns shape (N, H, W).\n",
        "        \"\"\"\n",
        "        B, C, H, W = embedding_vectors.size()\n",
        "        embedding_vectors = embedding_vectors.view(B, C, H * W).numpy()\n",
        "        dist_list: List[List[np.float64]] = []\n",
        "        for i in range(H * W):\n",
        "            mean = self.mean[:, i]\n",
        "            conv_inv = np.linalg.inv(self.cov[:, :, i])\n",
        "            dist = [mahalanobis(sample[:, i], mean, conv_inv)\n",
        "                    for sample in embedding_vectors]\n",
        "            dist_list.append(dist)\n",
        "\n",
        "        return np.array(dist_list).transpose(1, 0).reshape(B, H, W)\n",
        "\n",
        "    def prepare_anomaly_map(self, shape: Tuple[int, int], distances: FloatNDArray) -> FloatNDArray:\n",
        "        \"\"\"Upsample distances to `shape`, apply Gaussian smoothing, and normalize to [0,1].\n",
        "\n",
        "        For distances of shape (N, H, W) and `shape` equal to (H2, W2), returns shape (N, H2, W2).\n",
        "        \"\"\"\n",
        "        dists = torch.Tensor(distances).unsqueeze(1)\n",
        "        shape = (dists.shape[0],) + shape\n",
        "        score_map = cast(FloatNDArray, F.interpolate(\n",
        "            dists, size=shape[2], mode='bilinear', align_corners=False).squeeze().numpy())\n",
        "        for i in range(score_map.shape[0]):\n",
        "            score_map[i] = gaussian_filter(score_map[i], sigma=4)\n",
        "\n",
        "        min_score, max_score = score_map.min(), score_map.max()\n",
        "        return (score_map - min_score) / (max_score - min_score + 1e-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BufmMzabVZxu"
      },
      "source": [
        "### Let's see whether it works.\n",
        "Take a look to the `SAVE_PATH` to inspect the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HlfOLsv3VZxv",
        "outputId": "b24cb2fe-87a7-43c3-a87b-df8355b3f44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== bottle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 105/105 [00:07<00:00, 13.81it/s]\n",
            "Covariance estimation: 100%|██████████| 3136/3136 [00:00<00:00, 6449.88it/s]\n",
            "Feature extraction (test): 100%|██████████| 42/42 [00:03<00:00, 12.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Image AUROC: 0.998\n",
            "[TEST] Pixel AUROC: 0.981\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "seed_all(SEED)\n",
        "CLASS_NAMES = [\n",
        "            'bottle', #'metal_nut'\n",
        "            # 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather',\n",
        "            # 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n",
        "        ]\n",
        "BATCH_SIZE = 2\n",
        "RESIZE = 256 * 1\n",
        "CROP_SIZE = 224 * 1\n",
        "BACKBONE = \"resnet18\"\n",
        "NUMBER_OF_BACKBONE_FEATURES = 50\n",
        "MAX_NUMBER_OF_BACKBONE_FEATURES = 448\n",
        "\n",
        "run_timestamp = time.time()\n",
        "for class_name in CLASS_NAMES:\n",
        "    print('=' * 10, class_name)\n",
        "    SAVE_PATH = Path(f\"./results/{run_timestamp}/{class_name}\")\n",
        "\n",
        "    train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "    test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "    padim = PADIM(\n",
        "        backbone=BACKBONE,\n",
        "        device=DEVICE,\n",
        "        backbone_features_idx=sample_idx(NUMBER_OF_BACKBONE_FEATURES, MAX_NUMBER_OF_BACKBONE_FEATURES),\n",
        "        save_path=SAVE_PATH,\n",
        "        plot_metrics=True,\n",
        "    )\n",
        "\n",
        "    padim.train_and_test(\n",
        "        train_dataloader=train_dataloader,\n",
        "        test_dataloader=test_dataloader,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL00CE8iVZxw"
      },
      "source": [
        "# Task 1. Finding the right features (40%)\n",
        "\n",
        "The authors of the paper argue that it doesn't really matter how we choose a subset of features. Let's make some steps towards exploring whether it's true for three different classes (`bottle`, `transistor`, `metal_nut`).\n",
        "Design an experiment which will rank the ResNet18 features by its importance. To do so, we'll implement our variation of [permutation feature importance](https://scikit-learn.org/stable/modules/permutation_importance.html#outline-of-the-permutation-importance-algorithm) on a subset of features produced by the backbone.\n",
        "\n",
        "## 1.1 Preparing the data\n",
        "- Using the test dataset, create `val_dataloader` (every even sample from the original test dataset) and `test_dataloader` (every odd sample). `SubsetRandomSampler` might be handy here.\n",
        "- Then, create 3-fold cross validation-like process in which you'll train three PADIM models on the first 100 ResNet features in three equally sized subsets of train dataset in which you discard 1/3 of the data ($\\texttt{padim}_{k}\\texttt{.train}(\\texttt{train\\_dataloader}_k)$) (see below). Again, `SubsetRandomSampler` might be handy here.\n",
        "\n",
        "In other words, you should have:\n",
        "\n",
        "- for $k=0$, the first 10 images indexes from the train dataset we should train on are `[1, 2, 4, 5, 7, 8, 10, 11, 13, 14]`,\n",
        "- for $k=1$, that's `[0, 2, 3, 5, 6, 8, 9, 11, 12, 14]`,\n",
        "- and for $k=2$, that's `[0, 1, 3, 4, 6, 7, 9, 10, 12, 13]`.\n",
        "\n",
        "For val and train, you should have `[0, 2, 4, ...]` and `[1, 3, 5, ...]` respectively (from the test dataset).\n",
        "\n",
        "Don't worry about the sampling order.\n",
        "Use these names for DataLoaders `val_dataloader`, `test_dataloader`. For k-fold training, store dataloaders in `train_dataloaders: List[DataLoader]`, where each element represent different $k$.\n",
        "For each class, store the results in `dataloaders` dictionary (the variable is defined in the code below) - we will use this to check your solution.\n",
        "\n",
        "## 1.2 Calculating the importances\n",
        "- In a given fold, each $j$-th feature shall be ranked based on the pixel-wise AUROC difference between the output of that model ($s_{k} \\leftarrow \\texttt{padim}_{k}\\texttt{.test}(\\texttt{val\\_dataloader})$) and the output with the model with permuted $j$-th feature ($s_{k, j} \\leftarrow \\texttt{padim}_{k}\\texttt{.test\\_permutation\\_importance}(\\texttt{val\\_dataloader, features\\_to\\_permute=}[j])$). In practice you can pass all the numbers of features to permute (instead of 1-element list and do the loop inside the method. See also `test_permutation_importance` method stub above.\n",
        "- Implement `permute_feature` method as follows: given the tensor with embeddings with shape `[B, C, H, W]`, by permutation of the $j$-th feature we mean randomly swapped values for $C=j$. Although (ideally) the order of swapping shall be **different** for every image, we don't require you to strictly guarantee that you won't get the same permutation twice (what matters here is not using the same permutation for **every** sample - you can e.g. use distinct calls to a shuffling function for every sample). In other words, for every image $b$ and feature $j$ you need to shuffle the last two dimensions (marked as stars in `[b, j, *, *]`) in an (ideally) unique manner.\n",
        "- Then, calculate the mean importance $i$ averaged on these folds and plot weights importance for the class ($i_j \\leftarrow \\frac{1}{K} \\sum_{k} ( s_k -  s_{k, j} )$, where $K$ is the number of folds).\n",
        "- Append results in `results` dictionary, where keys are class names and values are the lists of averaged feature importances (from feature 0 to feature 99).\n",
        "\n",
        "## 1.3 Drawing conclusions\n",
        "\n",
        "- Finally, for every class train three models on the full training data and evaluate it on the `test_dataloader`. The first model shall use the first 10 features, the second shall use worst 10 features (in terms of feature importance), and the third shall contain the best 10 features.\n",
        "- Write your conclusions (with the things enlisted below in mind). Simply plotting charts or outputting logs without any comment doesn't qualify as an answer to a question.\n",
        "\n",
        "Note 1: Limit yourself to the first 100 features of ResNet18. If you want, you can go with all of available features instead of 100, but it'll take some time to calculate. Converting parts of the code to PyTorch and running on GPU might change a lot here, but this is not evaluated in this exercise. This experiment can be calculated without GPU in less than one hour anyway.\n",
        "\n",
        "Note 2: If you'd like to be fully covered, one needs to explore if the features are correlated, as this might bias the results of feature importance calculations. However, this is not evaluated in this task for the sake of simplicity (that is, examining the 100 first features without worrying about correlated features are enough to get 100% from this task)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LzYc9ExXVZxw"
      },
      "outputs": [],
      "source": [
        "# do not modify\n",
        "CLASS_NAMES = ['bottle'] # ['bottle', 'metal_nut', 'transistor'] \n",
        "\n",
        "BATCH_SIZE = 1\n",
        "RESIZE = 256 * 2 // 4\n",
        "CROP_SIZE = 224 * 2 // 4\n",
        "BACKBONE = \"resnet18\"\n",
        "NUMBER_OF_BACKBONE_FEATURES = 10\n",
        "MAX_NUMBER_OF_BACKBONE_FEATURES = 100  # 448\n",
        "folds = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3UHb3HymVZxx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1702820924.571866\n"
          ]
        }
      ],
      "source": [
        "seed_all(SEED)\n",
        "results = {c: [0] * MAX_NUMBER_OF_BACKBONE_FEATURES for c in CLASS_NAMES}\n",
        "\n",
        "run_timestamp = time.time()\n",
        "print(f\"{run_timestamp}\")\n",
        "\n",
        "idx_all_fatures = torch.Tensor(range(MAX_NUMBER_OF_BACKBONE_FEATURES)).int()\n",
        "idx_first_n_features = torch.Tensor(range(NUMBER_OF_BACKBONE_FEATURES)).int()\n",
        "\n",
        "dataloaders = {c: {\"val_dataloader\": None, \"test_dataloader\": None, \"train_dataloaders\": None} for c in CLASS_NAMES}\n",
        "\n",
        "# TODO: Your code for T1.1, T1.2, and T1.3 goes below. Don't forget to write `test_permutation_importance` and `permute_feature` above in the PADIM code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(0, dtype=torch.int32), tensor(1, dtype=torch.int32), tensor(2, dtype=torch.int32), tensor(3, dtype=torch.int32), tensor(4, dtype=torch.int32), tensor(5, dtype=torch.int32), tensor(6, dtype=torch.int32), tensor(7, dtype=torch.int32), tensor(8, dtype=torch.int32), tensor(9, dtype=torch.int32), tensor(10, dtype=torch.int32), tensor(11, dtype=torch.int32), tensor(12, dtype=torch.int32), tensor(13, dtype=torch.int32), tensor(14, dtype=torch.int32), tensor(15, dtype=torch.int32), tensor(16, dtype=torch.int32), tensor(17, dtype=torch.int32), tensor(18, dtype=torch.int32), tensor(19, dtype=torch.int32), tensor(20, dtype=torch.int32), tensor(21, dtype=torch.int32), tensor(22, dtype=torch.int32), tensor(23, dtype=torch.int32), tensor(24, dtype=torch.int32), tensor(25, dtype=torch.int32), tensor(26, dtype=torch.int32), tensor(27, dtype=torch.int32), tensor(28, dtype=torch.int32), tensor(29, dtype=torch.int32), tensor(30, dtype=torch.int32), tensor(31, dtype=torch.int32), tensor(32, dtype=torch.int32), tensor(33, dtype=torch.int32), tensor(34, dtype=torch.int32), tensor(35, dtype=torch.int32), tensor(36, dtype=torch.int32), tensor(37, dtype=torch.int32), tensor(38, dtype=torch.int32), tensor(39, dtype=torch.int32), tensor(40, dtype=torch.int32), tensor(41, dtype=torch.int32), tensor(42, dtype=torch.int32), tensor(43, dtype=torch.int32), tensor(44, dtype=torch.int32), tensor(45, dtype=torch.int32), tensor(46, dtype=torch.int32), tensor(47, dtype=torch.int32), tensor(48, dtype=torch.int32), tensor(49, dtype=torch.int32), tensor(50, dtype=torch.int32), tensor(51, dtype=torch.int32), tensor(52, dtype=torch.int32), tensor(53, dtype=torch.int32), tensor(54, dtype=torch.int32), tensor(55, dtype=torch.int32), tensor(56, dtype=torch.int32), tensor(57, dtype=torch.int32), tensor(58, dtype=torch.int32), tensor(59, dtype=torch.int32), tensor(60, dtype=torch.int32), tensor(61, dtype=torch.int32), tensor(62, dtype=torch.int32), tensor(63, dtype=torch.int32), tensor(64, dtype=torch.int32), tensor(65, dtype=torch.int32), tensor(66, dtype=torch.int32), tensor(67, dtype=torch.int32), tensor(68, dtype=torch.int32), tensor(69, dtype=torch.int32), tensor(70, dtype=torch.int32), tensor(71, dtype=torch.int32), tensor(72, dtype=torch.int32), tensor(73, dtype=torch.int32), tensor(74, dtype=torch.int32), tensor(75, dtype=torch.int32), tensor(76, dtype=torch.int32), tensor(77, dtype=torch.int32), tensor(78, dtype=torch.int32), tensor(79, dtype=torch.int32), tensor(80, dtype=torch.int32), tensor(81, dtype=torch.int32), tensor(82, dtype=torch.int32), tensor(83, dtype=torch.int32), tensor(84, dtype=torch.int32), tensor(85, dtype=torch.int32), tensor(86, dtype=torch.int32), tensor(87, dtype=torch.int32), tensor(88, dtype=torch.int32), tensor(89, dtype=torch.int32), tensor(90, dtype=torch.int32), tensor(91, dtype=torch.int32), tensor(92, dtype=torch.int32), tensor(93, dtype=torch.int32), tensor(94, dtype=torch.int32), tensor(95, dtype=torch.int32), tensor(96, dtype=torch.int32), tensor(97, dtype=torch.int32), tensor(98, dtype=torch.int32), tensor(99, dtype=torch.int32)]\n"
          ]
        }
      ],
      "source": [
        "print(list(idx_all_fatures))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T1.1\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "\n",
        "for class_name in CLASS_NAMES:\n",
        "    test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "    train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "    \n",
        "    odd_indices = list(range(len(test_dataset)))[::2]\n",
        "    even_indices = list(range(len(test_dataset)))[1::2]\n",
        "\n",
        "    val_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True, \n",
        "                                sampler=SubsetRandomSampler(even_indices))\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True,\n",
        "                                sampler=SubsetRandomSampler(odd_indices))\n",
        "    \n",
        "    train_dataloaders = []\n",
        "    for fold in range(folds):\n",
        "        train_indices = [idx for idx in list(range(len(train_dataset))) if idx % folds != fold]\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True,\n",
        "                                    sampler=SubsetRandomSampler(train_indices))\n",
        "        train_dataloaders.append(train_dataloader)\n",
        "\n",
        "    dataloaders[class_name] = {\"val_dataloader\": val_dataloader, \"test_dataloader\": test_dataloader, \"train_dataloaders\": train_dataloaders}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== bottle\n",
            "Fold: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 139/139 [00:04<00:00, 28.37it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 5434.00it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 25.51it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 27.19it/s]\n",
            "100%|██████████| 100/100 [01:53<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 139/139 [00:04<00:00, 28.01it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 5509.07it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 24.05it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 25.38it/s]\n",
            "100%|██████████| 100/100 [02:40<00:00,  1.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 140/140 [00:04<00:00, 28.39it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 5043.26it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 25.49it/s]\n",
            "Feature extraction (test): 100%|██████████| 41/41 [00:01<00:00, 26.51it/s]\n",
            "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
          ]
        }
      ],
      "source": [
        "# T1.2\n",
        "\n",
        "for class_name in CLASS_NAMES:\n",
        "    print('=' * 10, class_name)\n",
        "    val_dataloader = dataloaders[class_name][\"val_dataloader\"]\n",
        "    test_dataloader = dataloaders[class_name][\"test_dataloader\"]\n",
        "    train_dataloaders = dataloaders[class_name][\"train_dataloaders\"]\n",
        "\n",
        "    for fold in range(folds):\n",
        "        print(f\"Fold: {fold}\")\n",
        "        padim_k = PADIM(\n",
        "            backbone=BACKBONE,\n",
        "            device=DEVICE,\n",
        "            backbone_features_idx=idx_all_fatures,\n",
        "            save_path=SAVE_PATH,\n",
        "            plot_metrics=False,\n",
        "        )\n",
        "        padim_k.train(train_dataloaders[fold])\n",
        "        features_to_permute = list(range(MAX_NUMBER_OF_BACKBONE_FEATURES))\n",
        "        score_k = padim_k.test(val_dataloader)\n",
        "        score_k_j_list = padim_k.test_permutation_importance(val_dataloader, features_to_permute)\n",
        "        \n",
        "        for j in range(MAX_NUMBER_OF_BACKBONE_FEATURES):\n",
        "            results[class_name][j] += (score_k - score_k_j_list[j]) / folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== bottle\n",
            "========== first_10_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 209/209 [00:07<00:00, 28.17it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 40468.32it/s]\n",
            "Feature extraction (test): 100%|██████████| 42/42 [00:01<00:00, 26.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Image AUROC: 1.000\n",
            "[TEST] Pixel AUROC: 0.975\n",
            "========== most_important_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 209/209 [00:07<00:00, 29.12it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 40147.17it/s]\n",
            "Feature extraction (test): 100%|██████████| 42/42 [00:01<00:00, 26.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Image AUROC: 0.997\n",
            "[TEST] Pixel AUROC: 0.974\n",
            "========== least_important_features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature extraction (train): 100%|██████████| 209/209 [00:07<00:00, 28.51it/s]\n",
            "Covariance estimation: 100%|██████████| 784/784 [00:00<00:00, 40555.16it/s]\n",
            "Feature extraction (test): 100%|██████████| 42/42 [00:01<00:00, 26.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Image AUROC: 1.000\n",
            "[TEST] Pixel AUROC: 0.969\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# T1.3\n",
        "\n",
        "for class_name in CLASS_NAMES:\n",
        "    print('=' * 10, class_name)\n",
        "    train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "    feature_importance = results[class_name]\n",
        "    sorted_f_imp_idx = sorted(enumerate(feature_importance), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    feature_sets = {\n",
        "        \"first_10_features\" : list(range(10)),\n",
        "        \"most_important_features\" : [index for index, number in sorted_f_imp_idx[:10]],\n",
        "        \"least_important_features\" : [index for index, number in sorted_f_imp_idx[-10:]],\n",
        "    } \n",
        "\n",
        "    for feature_set_name, feature_set in feature_sets.items():\n",
        "        print(\"=\" * 10, feature_set_name)\n",
        "        padim = PADIM(\n",
        "            backbone=BACKBONE,\n",
        "            device=DEVICE,\n",
        "            backbone_features_idx=torch.Tensor(feature_set).int(),\n",
        "            save_path=SAVE_PATH,\n",
        "            plot_metrics=True,\n",
        "        )\n",
        "\n",
        "        padim.train_and_test(train_dataloader, dataloaders[class_name][\"test_dataloader\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### T1.3.: Thoughts and conclusion\n",
        "\n",
        "Our results indicate that specific choice of features doesn't seem to matter in the grand picture. My hypothesis is that resNet tries to encode the most important data through the consecutive layers and thus no matter from which layer we would choose our features the information relevant for classification is still encoded in them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "za2w3WO3VZxx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44, 95, 87, 60, 10, 51, 14, 25, 21, 57]\n",
            "[83, 62, 96, 64, 68, 45, 84, 91, 67, 35]\n",
            "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81]\n",
            "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82]\n",
            "[1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 70, 71, 73, 74, 76, 77, 79, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 127, 128, 130, 131, 133, 134, 136, 137, 139, 140, 142, 143, 145, 146, 148, 149, 151, 152, 154, 155, 157, 158, 160, 161, 163, 164, 166, 167, 169, 170, 172, 173, 175, 176, 178, 179, 181, 182, 184, 185, 187, 188, 190, 191, 193, 194, 196, 197, 199, 200, 202, 203, 205, 206, 208]\n",
            "[0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90, 92, 93, 95, 96, 98, 99, 101, 102, 104, 105, 107, 108, 110, 111, 113, 114, 116, 117, 119, 120, 122, 123, 125, 126, 128, 129, 131, 132, 134, 135, 137, 138, 140, 141, 143, 144, 146, 147, 149, 150, 152, 153, 155, 156, 158, 159, 161, 162, 164, 165, 167, 168, 170, 171, 173, 174, 176, 177, 179, 180, 182, 183, 185, 186, 188, 189, 191, 192, 194, 195, 197, 198, 200, 201, 203, 204, 206, 207]\n",
            "[0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 82, 84, 85, 87, 88, 90, 91, 93, 94, 96, 97, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 115, 117, 118, 120, 121, 123, 124, 126, 127, 129, 130, 132, 133, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 150, 151, 153, 154, 156, 157, 159, 160, 162, 163, 165, 166, 168, 169, 171, 172, 174, 175, 177, 178, 180, 181, 183, 184, 186, 187, 189, 190, 192, 193, 195, 196, 198, 199, 201, 202, 204, 205, 207, 208]\n"
          ]
        }
      ],
      "source": [
        "# Run at the end, but do not modify - we will use this to asses your output.\n",
        "for c in CLASS_NAMES:\n",
        "    s = pd.Series(results[c])\n",
        "    print(s.sort_values(ascending=False)[:10].index.tolist())\n",
        "    print(s.sort_values(ascending=True)[:10].index.tolist())\n",
        "\n",
        "def get_sorted_indices(loader):\n",
        "    loader.dataset.return_only_indices = True\n",
        "    indices = sorted([x.item() for x in loader])\n",
        "    loader.dataset.return_only_indices = False\n",
        "    return indices\n",
        "\n",
        "for c in CLASS_NAMES:\n",
        "    print(get_sorted_indices(dataloaders[c][\"val_dataloader\"]))\n",
        "    print(get_sorted_indices(dataloaders[c][\"test_dataloader\"]))\n",
        "    for v in dataloaders[c][\"train_dataloaders\"]:\n",
        "        print(get_sorted_indices(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qtn9ylbVZxx"
      },
      "source": [
        "# Task 2. Improving PADIM with Online Covariance Estimation\n",
        "\n",
        "This implementation of PADIM can be improved in numerous ways. In this exercise, you'll try to indicate its shortcomings and provide some means to mitigate them.\n",
        "\n",
        "#### 2.1. PADIM's training complexity (15%)\n",
        "\n",
        "- Identify the key operations contributing to the algorithm's training space complexity *in this implementation*. Don't focus on the backbone, as it is not the part of the algorithm (however, its output is).\n",
        "- Shortly discuss the implications for scalability. You can support your claims by charts if needed.\n",
        "\n",
        "*Hint: this doesn't need to be super formal analysis - it's about fiding the \"worst\" parts of this implementation. You can support your claims with a chart and brief description (e.g. \"X dominates the complexity, as it's quadratic.\")*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdODnlnsVZxx"
      },
      "source": [
        "```Your answer to task 2.1 goes here```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD9esI1fVZxx"
      },
      "outputs": [],
      "source": [
        "# Your code goes here (if needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by7h9sp3VZxx"
      },
      "source": [
        "#### 2.2 Online mean and covariance (35%)\n",
        "Implement a PyTorch version of [online covariance matrix estimation](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online) in the training as an alternative to the current method in PADIM.\n",
        "Calculate the mean in an online fashion as well.\n",
        "Your implementation shall run on the selected `torch.device` (such as GPU).\n",
        "No need to reimplement the testing routine to online in this exercise (although it'd be nice to have for Task 1), albeit small changes might be necessary (such as conversion from `torch.Tensor` to `np.ndarray`).\n",
        "\n",
        "Passing criteria:\n",
        "```python\n",
        "torch.allclose(padim_online.mean, torch.Tensor(padim_offline.mean).to(DEVICE), atol=0.01)\n",
        "torch.allclose(padim_online.cov, torch.Tensor(padim_offline.cov).to(DEVICE), atol=0.01)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-1wMyouVZxx"
      },
      "outputs": [],
      "source": [
        "class PADIMWithOnlineCovariance(PADIM):\n",
        "\n",
        "    ### TODO: Your code goes here\n",
        "    def __init__(\n",
        "            self,\n",
        "            backbone: str,\n",
        "            device: torch.device,\n",
        "            save_path: Path,\n",
        "            backbone_features_idx: List[int],\n",
        "            class_names=...,\n",
        "            plot_metrics=False,\n",
        "            ) -> None:\n",
        "        super().__init__(backbone, device, save_path, backbone_features_idx, class_names, plot_metrics)\n",
        "\n",
        "    def train(self, train_dataloader: DataLoader, C: int, H: int, W: int):\n",
        "        \"\"\"C, H, W come from the size of embeddings: [B, C, H, W]\"\"\"\n",
        "        pass\n",
        "\n",
        "    ### END OF YOUR CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TT0JEi5VZxx"
      },
      "outputs": [],
      "source": [
        "# do not modify\n",
        "seed_all(SEED)\n",
        "class_name = 'bottle'\n",
        "BATCH_SIZE = 1\n",
        "RESIZE = 256 * 1\n",
        "CROP_SIZE = 224 * 1\n",
        "BACKBONE = \"resnet18\"\n",
        "NUMBER_OF_BACKBONE_FEATURES = 30\n",
        "MAX_NUMBER_OF_BACKBONE_FEATURES = 448\n",
        "# DEVICE=\"cpu\"\n",
        "\n",
        "indices = sample_idx(NUMBER_OF_BACKBONE_FEATURES, MAX_NUMBER_OF_BACKBONE_FEATURES).to(DEVICE)\n",
        "\n",
        "run_timestamp = time.time()\n",
        "SAVE_PATH = Path(f\"./results/{run_timestamp}/{class_name}\")\n",
        "\n",
        "train_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=True, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "test_dataset = MVTecDataset(DATA_PATH, class_name=class_name, is_train=False, resize=RESIZE, cropsize=CROP_SIZE)\n",
        "val_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "\n",
        "padim_offline = PADIM(\n",
        "    backbone=BACKBONE,\n",
        "    device=DEVICE,\n",
        "    backbone_features_idx=indices,\n",
        "    save_path=SAVE_PATH,\n",
        "    plot_metrics=True,\n",
        ")\n",
        "padim_offline.train(train_dataloader)\n",
        "\n",
        "padim_online = PADIMWithOnlineCovariance(\n",
        "    backbone=BACKBONE,\n",
        "    device=DEVICE,\n",
        "    backbone_features_idx=indices,\n",
        "    save_path=SAVE_PATH,\n",
        "    plot_metrics=True,\n",
        ")\n",
        "padim_online.train(train_dataloader, NUMBER_OF_BACKBONE_FEATURES, int(CROP_SIZE/4), int(CROP_SIZE/4))\n",
        "\n",
        "torch.allclose(padim_online.mean, torch.Tensor(padim_offline.mean).to(DEVICE), atol=0.01) and torch.allclose(padim_online.cov, torch.Tensor(padim_offline.cov).to(DEVICE), atol=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQEY2gVfVZxx"
      },
      "source": [
        "#### 2.3 Performance experiments (10%)\n",
        "If you completed task 2.2, design experiments to empirically compare `space/memory` performance of PADIM training with both traditional and online covariance matrix estimation. Write short conclusions.\n",
        "\n",
        "#### 2.4 Bonus task (optional)\n",
        "You can also add similar experiments with conclusions with regard to the `time` complexity. This task is optional, but if you'll loose points elsewhere, this can help you to make up for some of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYH9l98tVZxy"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKuh7U-oVZxy"
      },
      "source": [
        "```Your conclusions go here```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-teaching",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
